"""
TÃœRKÃ‡E DÄ°YETÄ°SYEN LLM EÄÄ°TÄ°MÄ° Ä°Ã‡Ä°N GELÄ°ÅMÄ°Å PDF Ä°NDÄ°RÄ°CÄ°

ğŸ¯ Google Scholar'dan TÃ¼rkÃ§e beslenme/diyetetik alanÄ±nda akademik PDF'leri otomatik indirir.
ğŸ‡¹ğŸ‡· 113 TÃ¼rkÃ§e anahtar kelime ile kapsamlÄ± akademik literatÃ¼r toplama.
ğŸ“š TÃ¼rkÃ§e LLM model eÄŸitimi iÃ§in optimize edilmiÅŸ veri seti oluÅŸturur.
âš¡ GÃ¼venli bekleme mekanizmalarÄ± ile Google Scholar engellemelerine karÅŸÄ± korumalÄ±.

KullanÄ±m: python pdf_indir.py
"""

import requests
import random
import time
import json
import urllib.parse
import os
import re
from bs4 import BeautifulSoup
from tqdm import tqdm
from urllib.parse import urljoin, urlparse
from datetime import datetime

# TÃ¼rkÃ§e Diyetisyen/Beslenme alanÄ± anahtar kelimeleri
TURKCE_ANAHTAR_KELIMELER = [
    # Temel Beslenme Terimleri
    "beslenme bilimi", "diyetetik", "beslenme tedavisi", "klinik beslenme",
    "gÄ±da bilimi", "beslenme danÄ±ÅŸmanlÄ±ÄŸÄ±", "diyet tedavisi", "beslenme deÄŸerlendirmesi",
    "beslenme eÄŸitimi", "nutrisyon", "diyet planlamasÄ±", "beslenme analizi",
    
    # HastalÄ±k Spesifik Beslenme
    "diyabetik beslenme", "diyabet diyeti", "kardiyovaskÃ¼ler beslenme", "kalp hastalÄ±ÄŸÄ± diyeti",
    "obezite beslenme", "zayÄ±flama diyeti", "kanser beslenme", "onkoloji diyeti",
    "bÃ¶brek hastalÄ±ÄŸÄ± beslenme", "renal diyet", "karaciÄŸer hastalÄ±ÄŸÄ± beslenme", "hepatik diyet",
    "yeme bozukluklarÄ±", "anoreksia nervoza", "bulimia nervoza", "malnÃ¼trisyon",
    "beslenme yetersizliÄŸi", "protein enerji malnÃ¼trisyonu", "mikro besin eksikliÄŸi",
    
    # YaÅŸ GruplarÄ±na GÃ¶re Beslenme
    "Ã§ocuk beslenme", "pediatrik beslenme", "bebek beslenme", "infant beslenme",
    "adÃ¶lesan beslenme", "ergen beslenme", "yaÅŸlÄ± beslenme", "geriatrik beslenme",
    "okul Ã¶ncesi beslenme", "okul Ã§aÄŸÄ± beslenme", "yetiÅŸkin beslenme",
    
    # Ã–zel Durumlar
    "gebelik beslenme", "hamilelik diyeti", "emzirme beslenme", "laktasyon diyeti",
    "sporcu beslenme", "spor diyeti", "atletik beslenme", "egzersiz beslenme",
    "vejetaryen beslenme", "vegan beslenme", "bitkisel beslenme", "helal beslenme",
    
    # Besin Ã–ÄŸeleri
    "makro besin Ã¶ÄŸeleri", "mikro besin Ã¶ÄŸeleri", "vitaminler", "mineraller",
    "protein", "karbonhidrat", "yaÄŸ", "lif", "su", "enerji",
    "omega yaÄŸ asitleri", "antioksidanlar", "probiyotikler", "prebiyotikler",
    "fonksiyonel gÄ±dalar", "besin takviyeleri", "vitamin mineral desteÄŸi",
    
    # Beslenme DeÄŸerlendirmesi
    "beslenme taramasÄ±", "diyet analizi", "antropometrik Ã¶lÃ§Ã¼mler", "vÃ¼cut kompozisyonu",
    "beslenme biomarkerleri", "diyet hatÄ±rlama", "gÄ±da frekansÄ±", "porsiyon kontrolÃ¼",
    "kalori hesaplama", "besin deÄŸeri", "glisemik indeks", "metabolik sendrom",
    
    # TÃ¼rk MutfaÄŸÄ± ve KÃ¼ltÃ¼rel Beslenme
    "tÃ¼rk mutfaÄŸÄ± beslenme", "geleneksel tÃ¼rk yemekleri", "akdeniz diyeti tÃ¼rkiye",
    "tÃ¼rkiye beslenme durumu", "tÃ¼rk halkÄ± beslenme", "kÃ¼ltÃ¼rel beslenme",
    "anadolu mutfaÄŸÄ±", "tÃ¼rk gÄ±da kÃ¼ltÃ¼rÃ¼", "geleneksel gÄ±dalar",
    
    # GÄ±da GÃ¼venliÄŸi ve Teknolojisi
    "gÄ±da gÃ¼venliÄŸi", "gÄ±da hijyeni", "gÄ±da teknolojisi", "gÄ±da muhafaza",
    "gÄ±da zehirlenmesi", "gÄ±da alerjileri", "gÄ±da intoleransÄ±", "Ã§Ã¶lyak hastalÄ±ÄŸÄ±",
    "laktoz intoleransÄ±", "gÄ±da etiketleme", "organik gÄ±dalar",
    
    # Toplum SaÄŸlÄ±ÄŸÄ± ve Beslenme PolitikalarÄ±
    "toplum beslenme", "halk saÄŸlÄ±ÄŸÄ± beslenme", "beslenme politikalarÄ±", "okul beslenme programlarÄ±",
    "beslenme eÄŸitimi programlarÄ±", "beslenme rehberleri tÃ¼rkiye", "beslenme kÄ±lavuzu",
    "tÃ¼rkiye beslenme ve saÄŸlÄ±k araÅŸtÄ±rmasÄ±", "tÃ¼ber", "hacettepe beslenme"
]

# TÃ¼rkÃ§e Beslenme alanÄ±nda Ã¶nemli akademik dergiler ve kurumlar
TURKCE_BESLENME_KAYNAKLARI = [
    "Beslenme ve Diyet Dergisi",
    "TÃ¼rk Diyetisyenler DerneÄŸi", 
    "Hacettepe Ãœniversitesi Beslenme",
    "Ankara Ãœniversitesi Beslenme",
    "Ä°stanbul Ãœniversitesi Beslenme",
    "Ege Ãœniversitesi Beslenme",
    "BaÅŸkent Ãœniversitesi Beslenme",
    "TÃ¼rkiye Endokrinoloji ve Metabolizma DerneÄŸi",
    "TÃ¼rk Pediatri DerneÄŸi Beslenme"
]

# Ana indirme dizini
ANA_DIZIN = "Turkce_Beslenme_PDFleri"

# User-Agent listesi (Google Scholar iÃ§in)
USER_AGENT_LISTESI = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'
]

# GÃ¼venli indirme ayarlarÄ±
HER_ARAMA_MAKS_PDF = 25  # Her anahtar kelime iÃ§in maksimum PDF
HER_ARAMA_MAKS_SAYFA = 3  # Her arama iÃ§in maksimum sayfa
INDIRMELER_ARASI_BEKLEME = 8  # Ä°ndirmeler arasÄ± bekleme (saniye)
ARAMALAR_ARASI_BEKLEME = 20  # Google Scholar iÃ§in gÃ¼venli bekleme
SAYFALAR_ARASI_BEKLEME = 12  # Sayfa arasÄ± bekleme
NORMAL_TIMEOUT = 30  # HTTP timeout sÃ¼resi

# Google Scholar GiriÅŸ AyarlarÄ±
SCHOLAR_LOGIN_ENABLED = False  # True yaparak giriÅŸ sistemini aktifleÅŸtirin
COOKIES_FILE = "scholar_cookies.json"  # Session cookies dosyasÄ±

# GiriÅŸ session'Ä± iÃ§in global requests session
scholar_session = None

def turkce_scholar_url_olustur(anahtar_kelime, sayfa_no=0, yil_baslangic=2010):
    """TÃ¼rkÃ§e Google Scholar arama URL'si oluÅŸturur"""
    base_url = "https://scholar.google.com.tr/scholar"
    params = {
        'q': anahtar_kelime,
        'hl': 'tr',  # TÃ¼rkÃ§e arayÃ¼z
        'lr': 'lang_tr',  # TÃ¼rkÃ§e dil tercihi
        'as_sdt': '0,5',
        'as_vis': '1',
        'as_ylo': str(yil_baslangic),
        'start': str(sayfa_no * 10)
    }
    
    url = base_url + "?"
    for key, value in params.items():
        url += f"{key}={urllib.parse.quote(str(value))}&"
    
    return url.rstrip('&')

def makale_bilgilerini_cikar(sonuc_div):
    """TÃ¼rkÃ§e makale bilgilerini Ã§Ä±karÄ±r"""
    try:
        # BaÅŸlÄ±k
        baslik_elem = sonuc_div.find('h3', class_='gs_rt')
        baslik = baslik_elem.get_text().strip() if baslik_elem else "Bilinmeyen BaÅŸlÄ±k"
        
        # Yazarlar ve yayÄ±n bilgisi
        yazar_elem = sonuc_div.find('div', class_='gs_a')
        yazar_bilgisi = yazar_elem.get_text().strip() if yazar_elem else "Bilinmeyen Yazarlar"
        
        # Ã–zet
        ozet_elem = sonuc_div.find('div', class_='gs_rs')
        ozet = ozet_elem.get_text().strip() if ozet_elem else ""
        
        # AtÄ±f sayÄ±sÄ±
        atif_elem = sonuc_div.find('a', string=lambda text: text and ('atÄ±f' in text.lower() or 'cited by' in text.lower()))
        if not atif_elem:
            atif_elem = sonuc_div.find('a', href=lambda href: href and 'cites' in href)
        atiflar = atif_elem.get_text().strip() if atif_elem else "0 atÄ±f"
        
        return {
            'baslik': baslik,
            'yazarlar': yazar_bilgisi,
            'ozet': ozet,
            'atiflar': atiflar
        }
    except Exception as e:
        return {
            'baslik': "Bilinmeyen BaÅŸlÄ±k",
            'yazarlar': "Bilinmeyen Yazarlar", 
            'ozet': "",
            'atiflar': "0 atÄ±f"
        }

def turkce_beslenme_kontrolu(makale_bilgisi):
    """Makalenin TÃ¼rkÃ§e beslenme alanÄ±yla ilgili olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
    kontrol_metni = (makale_bilgisi['baslik'] + " " + makale_bilgisi['ozet']).lower()
    
    turkce_beslenme_terimleri = [
        'beslenme', 'diyet', 'gÄ±da', 'besin', 'vitamin', 'mineral',
        'obezite', 'diyabet', 'kalp', 'kardiyovaskÃ¼ler', 'metabolik',
        'yeme', 'yemek', 'kalori', 'protein', 'karbonhidrat', 'yaÄŸ',
        'lif', 'antioksidan', 'diyetisyen', 'nutrisyon', 'saÄŸlÄ±k',
        'Ã§ocuk', 'yaÅŸlÄ±', 'gebelik', 'sporcu', 'hastalÄ±k', 'tedavi'
    ]
    
    return any(terim in kontrol_metni for terim in turkce_beslenme_terimleri)

def pdf_indir_ve_kaydet(pdf_url, dosya_adi, makale_bilgisi):
    """PDF indirir ve TÃ¼rkÃ§e meta verileri kaydeder"""
    try:
        print(f"ğŸ“¥ PDF indiriliyor: {pdf_url}")
        
        # GÃ¼venli istek gÃ¶nder
        response = guvenli_istek_gonder(pdf_url)
        
        if not response:
            print(f"âŒ PDF indirme baÅŸarÄ±sÄ±z: {pdf_url}")
            return False
        
        # Content-Type kontrolÃ¼
        content_type = response.headers.get('content-type', '').lower()
        if 'pdf' not in content_type and not pdf_url.lower().endswith('.pdf'):
            print("âŒ Ä°Ã§erik PDF deÄŸil")
            return False
        
        # PDF boyut kontrolÃ¼ (Ã§ok kÃ¼Ã§Ã¼k dosyalarÄ± reddet)
        content_length = response.headers.get('content-length')
        if content_length and int(content_length) < 1024:  # 1KB'dan kÃ¼Ã§Ã¼k
            print("âŒ Dosya Ã§ok kÃ¼Ã§Ã¼k, muhtemelen PDF deÄŸil")
            return False
        
        # PDF indir
        with open(dosya_adi, "wb") as f:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
        
        # PDF dosya boyutunu kontrol et
        if os.path.getsize(dosya_adi) < 1024:
            print("âŒ Ä°ndirilen dosya Ã§ok kÃ¼Ã§Ã¼k, siliniyor")
            os.remove(dosya_adi)
            return False
        
        # TÃ¼rkÃ§e meta veri dosyasÄ± oluÅŸtur
        meta_dosya_adi = dosya_adi.replace('.pdf', '_bilgiler.json')
        meta_veri = {
            'dosya_adi': os.path.basename(dosya_adi),
            'indirilme_tarihi': datetime.now().isoformat(),
            'kaynak_url': pdf_url,
            'dosya_boyutu': os.path.getsize(dosya_adi),
            'makale_bilgileri': makale_bilgisi
        }
        
        with open(meta_dosya_adi, 'w', encoding='utf-8') as f:
            json.dump(meta_veri, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        print(f"âŒ Ä°ndirme hatasÄ±: {e}")
        return False

def akilli_bekleme(bekleme_turu="normal", ekstra_faktor=1.0):
    """AkÄ±llÄ± ve rastgele bekleme sistemi"""
    if bekleme_turu == "arama":
        temel_bekleme = ARAMALAR_ARASI_BEKLEME
    elif bekleme_turu == "sayfa":
        temel_bekleme = SAYFALAR_ARASI_BEKLEME
    elif bekleme_turu == "indirme":
        temel_bekleme = INDIRMELER_ARASI_BEKLEME
    else:
        temel_bekleme = 5
    
    # Rastgele varyasyon ekle (%50-150 arasÄ±)
    rastgele_faktor = random.uniform(0.5, 1.5)
    toplam_bekleme = temel_bekleme * rastgele_faktor * ekstra_faktor
    
    if toplam_bekleme > 3:
        print(f"â° {toplam_bekleme:.1f} saniye bekleniyor...")
    
    time.sleep(toplam_bekleme)

def anahtar_kelime_ara_ve_indir(anahtar_kelime, maks_sayfa=HER_ARAMA_MAKS_SAYFA):
    """Bir TÃ¼rkÃ§e anahtar kelime iÃ§in arama yapar ve PDF'leri indirir"""
    print(f"\nğŸ” Anahtar kelime: '{anahtar_kelime}'")
    
    # TÃ¼rkÃ§e klasÃ¶r oluÅŸtur
    guvenli_kelime = re.sub(r'[^\w\s-]', '', anahtar_kelime).strip()
    guvenli_kelime = re.sub(r'[-\s]+', '_', guvenli_kelime)
    kelime_klasoru = os.path.join(ANA_DIZIN, guvenli_kelime)
    os.makedirs(kelime_klasoru, exist_ok=True)
    
    toplam_indirilen = 0
    
    for sayfa in range(maks_sayfa):
        # Her sayfa arasÄ± gÃ¼venli bekleme
        if sayfa > 1:
            akilli_bekleme("sayfa")
        
        # Google Scholar sayfasÄ±nÄ± al
        scholar_url = turkce_scholar_url_olustur(anahtar_kelime, sayfa_no=sayfa)
        print(f"ğŸŒ URL: {scholar_url}")
        
        response = guvenli_istek_gonder(scholar_url)
        
        if not response:
            print(f"âŒ Sayfa {sayfa + 1} yÃ¼klenemedi")
            continue
                
        soup = BeautifulSoup(response.content, "html.parser")
        
        # SonuÃ§ divlerini bul
        sonuclar = soup.find_all("div", class_="gs_r gs_or gs_scl")
        if not sonuclar:
            sonuclar = soup.find_all("div", class_="gs_ri")
        
        if not sonuclar:
            print(f"âŒ Sayfa {sayfa + 1}'de sonuÃ§ bulunamadÄ±")
            # Captcha kontrolÃ¼
            if "captcha" in response.text.lower() or "robot" in response.text.lower():
                print("ğŸ¤– Captcha algÄ±landÄ±! Uzun bekleme yapÄ±lÄ±yor...")
                time.sleep(300)  # 5 dakika bekle
            break
        
        sayfa_indirilen = 0
        
        for i, sonuc_div in enumerate(sonuclar):
            if sayfa_indirilen >= HER_ARAMA_MAKS_PDF:
                break
                
            # Makale bilgilerini Ã§Ä±kar
            makale_bilgisi = makale_bilgilerini_cikar(sonuc_div)
            
            # TÃ¼rkÃ§e beslenme alanÄ±yla ilgili mi kontrol et
            if not turkce_beslenme_kontrolu(makale_bilgisi):
                print(f"â­ï¸ GeÃ§iliyor: {makale_bilgisi['baslik'][:40]}... (ilgisiz)")
                continue
            
            print(f"ğŸ“– Ä°ÅŸleniyor: {makale_bilgisi['baslik'][:50]}...")
            
            # PDF linklerini bul
            pdf_linkleri = []
            for link in sonuc_div.find_all("a", href=True):
                href = link["href"]
                link_metni = link.get_text().strip()
                
                if "[PDF]" in link_metni or "PDF" in link_metni.upper():
                    if href.startswith("/"):
                        pdf_url = urljoin("https://scholar.google.com.tr", href)
                    else:
                        pdf_url = href
                    pdf_linkleri.append(pdf_url)
            
            # PDF'leri indir
            for j, pdf_url in enumerate(pdf_linkleri):
                if sayfa_indirilen >= HER_ARAMA_MAKS_PDF:
                    break
                    
                dosya_adi = os.path.join(kelime_klasoru, f"{guvenli_kelime}_s{sayfa+1}_{i+1}_{j+1}.pdf")
                
                if pdf_indir_ve_kaydet(pdf_url, dosya_adi, makale_bilgisi):
                    sayfa_indirilen += 1
                    toplam_indirilen += 1
                    print(f"âœ… Ä°ndirildi: {makale_bilgisi['baslik'][:50]}...")
                
                # Ä°ndirme sonrasÄ± bekleme
                akilli_bekleme(bekleme_turu="indirme")
        
        print(f"ğŸ“Š Sayfa {sayfa + 1}: {sayfa_indirilen} PDF indirildi")
        
        if sayfa < maks_sayfa - 1:
            akilli_bekleme(bekleme_turu="sayfa")
            
    print(f"âœ… '{anahtar_kelime}' iÃ§in toplam {toplam_indirilen} PDF indirildi")
    return toplam_indirilen

def guvenli_istek_gonder(url, maks_deneme=3):
    """GÃ¼venli HTTP isteÄŸi gÃ¶nderir"""
    
    headers = {
        'User-Agent': random.choice(USER_AGENT_LISTESI),
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'no-cache',
        'Pragma': 'no-cache'
    }
    
    print("ğŸŒ HTTP isteÄŸi gÃ¶nderiliyor...")
    for deneme in range(maks_deneme):
        try:
            # Rastgele user agent seÃ§
            headers['User-Agent'] = random.choice(USER_AGENT_LISTESI)
            
            response = requests.get(url, headers=headers, timeout=NORMAL_TIMEOUT)
            
            if response.status_code == 200:
                print("âœ… Ä°stek baÅŸarÄ±lÄ±!")
                return response
            elif response.status_code == 429:
                bekleme = 60 + (deneme * 30)
                print(f"âš ï¸ Rate limit algÄ±landÄ±, {bekleme} saniye bekleniyor...")
                time.sleep(bekleme)
            elif response.status_code == 403:
                print("âš ï¸ EriÅŸim engellendi (403), daha uzun bekleme yapÄ±lacak...")
                time.sleep(120)  # 2 dakika bekle
            else:
                print(f"âš ï¸ HTTP {response.status_code}")
                
        except requests.exceptions.Timeout:
            print(f"â° Zaman aÅŸÄ±mÄ± (deneme {deneme + 1})")
            if deneme < maks_deneme - 1:
                time.sleep(15)
        except Exception as e:
            print(f"âŒ Ä°stek deneme {deneme + 1} baÅŸarÄ±sÄ±z: {e}")
            if deneme < maks_deneme - 1:
                bekleme = 15 + (deneme * 10)
                time.sleep(bekleme)
    
    print("âŒ TÃ¼m baÄŸlantÄ± denemeleri baÅŸarÄ±sÄ±z!")
    return None

def cookies_kaydet(session, dosya_yolu):
    """Session cookies'lerini dosyaya kaydet"""
    try:
        cookies_dict = {}
        for cookie in session.cookies:
            cookies_dict[cookie.name] = cookie.value
        
        with open(dosya_yolu, 'w', encoding='utf-8') as f:
            json.dump(cookies_dict, f, ensure_ascii=False, indent=2)
        print(f"âœ… Cookies kaydedildi: {dosya_yolu}")
        return True
    except Exception as e:
        print(f"âŒ Cookies kaydetme hatasÄ±: {e}")
        return False

def cookies_yukle(session, dosya_yolu):
    """Dosyadan cookies'leri yÃ¼kle"""
    try:
        if not os.path.exists(dosya_yolu):
            print(f"âš ï¸ Cookies dosyasÄ± bulunamadÄ±: {dosya_yolu}")
            return False
            
        with open(dosya_yolu, 'r', encoding='utf-8') as f:
            cookies_dict = json.load(f)
        
        for name, value in cookies_dict.items():
            session.cookies.set(name, value, domain='.google.com')
            session.cookies.set(name, value, domain='.scholar.google.com')
            session.cookies.set(name, value, domain='.scholar.google.com.tr')
        
        print(f"âœ… Cookies yÃ¼klendi: {dosya_yolu}")
        return True
    except Exception as e:
        print(f"âŒ Cookies yÃ¼kleme hatasÄ±: {e}")
        return False

def scholar_session_baslat():
    """Google Scholar iÃ§in giriÅŸ session'Ä± baÅŸlat"""
    global scholar_session
    
    if not SCHOLAR_LOGIN_ENABLED:
        print("â„¹ï¸ Scholar giriÅŸ sistemi pasif")
        return None
    
    try:
        scholar_session = requests.Session()
        
        # Temel headers
        scholar_session.headers.update({
            'User-Agent': random.choice(USER_AGENT_LISTESI),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        # KaydedilmiÅŸ cookies'leri yÃ¼kle
        if cookies_yukle(scholar_session, COOKIES_FILE):
            # Session'Ä± test et
            test_url = "https://scholar.google.com.tr/"
            response = scholar_session.get(test_url, timeout=30)
            
            if response.status_code == 200:
                # GiriÅŸ yapÄ±lmÄ±ÅŸ mÄ± kontrol et
                if "GiriÅŸ" not in response.text and ("Ã‡Ä±kÄ±ÅŸ" in response.text or "hesap" in response.text.lower()):
                    print("âœ… Google Scholar giriÅŸ session'Ä± aktif!")
                    return scholar_session
                else:
                    print("âš ï¸ Cookies eski, yeniden giriÅŸ gerekli")
            else:
                print(f"âš ï¸ Session test baÅŸarÄ±sÄ±z: {response.status_code}")
        
        print("ğŸ” Manuel Google Scholar giriÅŸ gerekli")
        return scholar_session
        
    except Exception as e:
        print(f"âŒ Scholar session baÅŸlatma hatasÄ±: {e}")
        return None

def manuel_giris_rehberi():
    """Manuel giriÅŸ iÃ§in rehber gÃ¶ster"""
    print("\n" + "="*80)
    print("ğŸ” GOOGLE SCHOLAR MANuel GÄ°RÄ°Å REHBERÄ°")
    print("="*80)
    print("1. Browser'Ä±nÄ±zda https://scholar.google.com.tr/ adresine gidin")
    print("2. Google hesabÄ±nÄ±z ile giriÅŸ yapÄ±n")
    print("3. Herhangi bir arama yapÄ±n (Ã¶rn: 'beslenme bilimi')")
    print("4. F12 basÄ±p Developer Tools'u aÃ§Ä±n")
    print("5. Network tab'Ä±na gidin")
    print("6. Bir PDF linkine tÄ±klayÄ±n")
    print("7. Ä°steklerde 'Headers' kÄ±smÄ±ndan 'Cookie' deÄŸerini kopyalayÄ±n")
    print("8. AÅŸaÄŸÄ±daki kodu Ã§alÄ±ÅŸtÄ±rÄ±n:")
    print("\n```python")
    print("# KopyaladÄ±ÄŸÄ±nÄ±z cookie string'ini buraya yapÄ±ÅŸtÄ±rÄ±n")
    print('cookie_string = "NID=xxx; GSP=xxx; ..."')
    print("import requests, json")
    print("session = requests.Session()")
    print("for cookie in cookie_string.split(';'):")
    print("    if '=' in cookie:")
    print("        name, value = cookie.strip().split('=', 1)")
    print("        session.cookies.set(name, value)")
    print("# Session'Ä± test et")
    print("response = session.get('https://scholar.google.com.tr/')")
    print("print('GiriÅŸ baÅŸarÄ±lÄ±!' if response.status_code == 200 else 'Hata!')")
    print("```")
    print("="*80)
    print("\nğŸ’¡ Daha kolay yÃ¶ntem iÃ§in Selenium kullanabilirsiniz:")
    print("   pip install selenium")
    print("   (Otomatik giriÅŸ kodu eklenecek)")
    print("="*80)

def main():
    """Ana Ã§alÄ±ÅŸma fonksiyonu"""
    print("ğŸš€ TÃ¼rkÃ§e Diyetisyen LLM EÄŸitimi iÃ§in PDF Ä°ndirici BaÅŸlatÄ±lÄ±yor...")
    print(f"ğŸ“‚ Ana dizin: {ANA_DIZIN}")
    print(f"ğŸ” Toplam {len(TURKCE_ANAHTAR_KELIMELER)} TÃ¼rkÃ§e anahtar kelime iÅŸlenecek")
    print("================================================================================")
    print("ğŸ“Š GÃœVENLÄ° BEKLEME SÃœRELERÄ° AKTÄ°F")
    print("ğŸ“Š Her indirme arasÄ±: 8 saniye")
    print("ğŸ” Her arama arasÄ±: 20 saniye") 
    print("ğŸ“„ Her sayfa arasÄ±: 12 saniye")
    print("â° HTTP timeout: 30 saniye")
    print("================================================================================")

    os.makedirs(ANA_DIZIN, exist_ok=True)
    
    toplam_indirilen = 0
    basarili_kelimeler = 0
    
    # TÃ¼rkÃ§e istatistik dosyasÄ± oluÅŸtur
    istatistik_dosyasi = os.path.join(ANA_DIZIN, "turkce_indirme_istatistikleri.json")
    baslangic_zamani = datetime.now()
    istatistikler = {
        "baslangic_zamani": baslangic_zamani.strftime("%Y-%m-%d %H:%M:%S"),
        "bitis_zamani": None,
        "toplam_sure_dakika": None,
        "toplam_anahtar_kelime": len(TURKCE_ANAHTAR_KELIMELER),
        "basarili_anahtar_kelime": 0,
        "toplam_indirilen_pdf": 0,
        "baglanti_modu": "Normal HTTP BaÄŸlantÄ±sÄ±",
        "ana_dizin": ANA_DIZIN,
        "basarili_anahtar_kelimeler": []
    }
    
    for i, anahtar_kelime in enumerate(TURKCE_ANAHTAR_KELIMELER, 1):
        print(f"\n{'='*30} ANAHTAR KELÄ°ME {i}/{len(TURKCE_ANAHTAR_KELIMELER)} {'='*30}")
        
        # Her anahtar kelime arasÄ± gÃ¼venli bekleme
        if i > 1:
            akilli_bekleme("arama")
        
        try:
            indirilen_sayi = anahtar_kelime_ara_ve_indir(anahtar_kelime)
            toplam_indirilen += indirilen_sayi
            
            if indirilen_sayi > 0:
                basarili_kelimeler += 1
            
            # Ä°statistikleri gÃ¼ncelle
            istatistikler['basarili_anahtar_kelime'] = basarili_kelimeler
            istatistikler['toplam_indirilen_pdf'] = toplam_indirilen
            istatistikler['basarili_anahtar_kelimeler'].append(anahtar_kelime)
            
            # Ä°statistikleri kaydet
            with open(istatistik_dosyasi, 'w', encoding='utf-8') as f:
                json.dump(istatistikler, f, ensure_ascii=False, indent=2)
            
            if i < len(TURKCE_ANAHTAR_KELIMELER):
                akilli_bekleme(bekleme_turu="arama")
                
        except KeyboardInterrupt:
            print("\nâš ï¸ KullanÄ±cÄ± tarafÄ±ndan durduruldu.")
            break
        except Exception as e:
            print(f"âŒ Beklenmeyen hata: {e}")
            continue
    
    # Son istatistikler
    bitis_zamani = datetime.now()
    sure_dakika = round((bitis_zamani - baslangic_zamani).total_seconds() / 60, 2)
    istatistikler['bitis_zamani'] = bitis_zamani.strftime("%Y-%m-%d %H:%M:%S")
    istatistikler['toplam_sure_dakika'] = sure_dakika
    with open(istatistik_dosyasi, 'w', encoding='utf-8') as f:
        json.dump(istatistikler, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*80}")
    print("ğŸ“Š TÃœRKÃ‡E DÄ°YETÄ°SYEN LLM PDF Ä°NDÄ°RME Ã–ZETÄ°")
    print("================================================================================")
    print(f"âœ… BaÅŸarÄ±lÄ± anahtar kelimeler: {basarili_kelimeler}/{len(TURKCE_ANAHTAR_KELIMELER)}")
    print(f"ğŸ“„ Toplam indirilen PDF: {toplam_indirilen}")
    print(f"ğŸŒ BaÄŸlantÄ± modu: Normal HTTP")
    print(f"ğŸ“‚ Ana dizin: {ANA_DIZIN}")
    print(f"ğŸ“Š Ä°statistik dosyasÄ±: {istatistik_dosyasi}")
    
    print("\nğŸ’¡ DAHA HIZLI Ä°NDÄ°RME Ã–NERÄ°LERÄ°:")
    print("   - VPN kullanarak IP deÄŸiÅŸtirin")
    print("   - Gece saatlerinde Ã§alÄ±ÅŸtÄ±rÄ±n (23:00-07:00)")
    print("   - FarklÄ± kategorileri farklÄ± gÃ¼nlerde iÅŸleyin")
    print("   - GÃ¼nde 100-200 PDF ile sÄ±nÄ±rlandÄ±rÄ±n")
    
    print("ğŸ‰ TÃ¼rkÃ§e Diyetisyen LLM eÄŸitim veri seti hazÄ±r!")

if __name__ == "__main__":
    main() 
